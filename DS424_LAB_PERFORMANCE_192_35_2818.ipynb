{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meherdurdana/Data-Science/blob/main/DS424_LAB_PERFORMANCE_192_35_2818.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpFa4OHM6wMJ"
      },
      "source": [
        "\n",
        "# LAB PERFORMANCE\n",
        "---\n",
        "---\n",
        "<B> Machine Learning Driven Data Analysis II and Communicating Data Insights Lab </B>\n",
        "`Course Code: DS424`\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "<u> Submitted By: </u>\n",
        "##### Meher Durdana Khan Raisa\n",
        "ID: 192-35-2818"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ9HoE85LtT-"
      },
      "source": [
        "Question 1\n",
        "---\n",
        "**Build an image classification model and predict MNIST Digits using Wide and Deep Neural Network. Your should use callback functions to implement early stopping and save the best model into appropriate format. Report the training and test accuracy and other evaluation metrics.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec544QKd6CkK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scirkoso7u7g",
        "outputId": "fc3ed338-6252-493c-aa01-8a832ac8b5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GajEJ4eS91K1"
      },
      "source": [
        "define the architecture of the Wide and Deep Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QOg7pu98Omf"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(28, 28))\n",
        "flatten_layer = keras.layers.Flatten()(input_layer)\n",
        "wide_branch = Dense(128, activation='relu')(flatten_layer)\n",
        "wide_branch = Dense(64, activation='relu')(wide_branch)\n",
        "deep_branch = Dense(128, activation='relu')(flatten_layer)\n",
        "deep_branch = Dense(128, activation='relu')(deep_branch)\n",
        "deep_branch = Dense(64, activation='relu')(deep_branch)\n",
        "\n",
        "concat_layer = Concatenate()([wide_branch, deep_branch])\n",
        "output_layer = Dense(10, activation='softmax')(concat_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4bqK95z-IeA"
      },
      "source": [
        "setting up early stopping and model checkpoint callbacks to monitor the training and save the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUcF7pHh-Cmw"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L7DfWJb-TrI",
        "outputId": "c30e28b2-c956-4072-c2b9-4d74b2b7e4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.9089\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95867, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 0.3175 - accuracy: 0.9096 - val_loss: 0.1424 - val_accuracy: 0.9587\n",
            "Epoch 2/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9647\n",
            "Epoch 2: val_accuracy improved from 0.95867 to 0.96425, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1184 - accuracy: 0.9647 - val_loss: 0.1164 - val_accuracy: 0.9643\n",
            "Epoch 3/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9770\n",
            "Epoch 3: val_accuracy improved from 0.96425 to 0.96867, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0761 - accuracy: 0.9770 - val_loss: 0.1029 - val_accuracy: 0.9687\n",
            "Epoch 4/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9829\n",
            "Epoch 4: val_accuracy improved from 0.96867 to 0.97175, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
            "Epoch 5/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9873\n",
            "Epoch 5: val_accuracy improved from 0.97175 to 0.97617, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 0.0836 - val_accuracy: 0.9762\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9909\n",
            "Epoch 6: val_accuracy did not improve from 0.97617\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.0874 - val_accuracy: 0.9748\n",
            "Epoch 7/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9923\n",
            "Epoch 7: val_accuracy improved from 0.97617 to 0.97783, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
            "Epoch 8/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9943\n",
            "Epoch 8: val_accuracy did not improve from 0.97783\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0965 - val_accuracy: 0.9754\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L59cOya-Zvv",
        "outputId": "127b5c03-9300-4a2f-d21b-4bb5d22490bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9793\n",
            "Test Accuracy: 0.9793000221252441\n"
          ]
        }
      ],
      "source": [
        "best_model = keras.models.load_model('best_model.h5')\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test Accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DtquIxt_Pso",
        "outputId": "d048e341-b933-479c-f834-62e225d67140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step\n",
            "Precision: 0.99877954\n",
            "Recall: 0.99800444\n",
            "F1 Score: 0.99839187\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(x_test)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)\n",
        "true_labels = tf.argmax(y_test, axis=1)\n",
        "\n",
        "precision = tf.keras.metrics.Precision()(true_labels, predicted_labels)\n",
        "recall = tf.keras.metrics.Recall()(true_labels, predicted_labels)\n",
        "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
        "\n",
        "print('Precision:', precision.numpy())\n",
        "print('Recall:', recall.numpy())\n",
        "print('F1 Score:', f1_score.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyq686EdAzf0"
      },
      "source": [
        "Question 2\n",
        "---\n",
        "**This time we used diffrent activation function like teanh, sigmoid insted of relu used before.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuuyEW13_dWi"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(28, 28))\n",
        "\n",
        "flatten_layer = keras.layers.Flatten()(input_layer)\n",
        "\n",
        "wide_branch = Dense(128, activation='tanh', kernel_initializer='glorot_uniform')(flatten_layer)\n",
        "wide_branch = Dense(64, activation='tanh', kernel_initializer='glorot_uniform')(wide_branch)\n",
        "\n",
        "deep_branch = Dense(128, activation='sigmoid', kernel_initializer='he_uniform')(flatten_layer)\n",
        "deep_branch = Dense(128, activation='sigmoid', kernel_initializer='he_uniform')(deep_branch)\n",
        "deep_branch = Dense(64, activation='sigmoid', kernel_initializer='he_uniform')(deep_branch)\n",
        "\n",
        "concat_layer = Concatenate()([wide_branch, deep_branch])\n",
        "\n",
        "output_layer = Dense(10, activation='softmax')(concat_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kv0fDX1BWAT"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt3zRe2FBaZT",
        "outputId": "cebd8020-8e2c-47f8-a619-2404e3c6d1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.8872\n",
            "Epoch 1: val_accuracy improved from -inf to 0.93842, saving model to best_model.h5\n",
            "375/375 [==============================] - 6s 12ms/step - loss: 0.4153 - accuracy: 0.8873 - val_loss: 0.2145 - val_accuracy: 0.9384\n",
            "Epoch 2/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9465\n",
            "Epoch 2: val_accuracy improved from 0.93842 to 0.95558, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1816 - accuracy: 0.9466 - val_loss: 0.1511 - val_accuracy: 0.9556\n",
            "Epoch 3/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9619\n",
            "Epoch 3: val_accuracy improved from 0.95558 to 0.96308, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1295 - accuracy: 0.9620 - val_loss: 0.1289 - val_accuracy: 0.9631\n",
            "Epoch 4/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9720\n",
            "Epoch 4: val_accuracy improved from 0.96308 to 0.96925, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0970 - accuracy: 0.9720 - val_loss: 0.1080 - val_accuracy: 0.9693\n",
            "Epoch 5/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9773\n",
            "Epoch 5: val_accuracy improved from 0.96925 to 0.97083, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0764 - accuracy: 0.9773 - val_loss: 0.0978 - val_accuracy: 0.9708\n",
            "Epoch 6/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9824\n",
            "Epoch 6: val_accuracy improved from 0.97083 to 0.97100, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0598 - accuracy: 0.9824 - val_loss: 0.0971 - val_accuracy: 0.9710\n",
            "Epoch 7/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9868\n",
            "Epoch 7: val_accuracy improved from 0.97100 to 0.97275, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.0901 - val_accuracy: 0.9728\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9903\n",
            "Epoch 8: val_accuracy improved from 0.97275 to 0.97492, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0371 - accuracy: 0.9903 - val_loss: 0.0870 - val_accuracy: 0.9749\n",
            "Epoch 9/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9918\n",
            "Epoch 9: val_accuracy did not improve from 0.97492\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 0.0889 - val_accuracy: 0.9732\n",
            "Epoch 10/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9946\n",
            "Epoch 10: val_accuracy improved from 0.97492 to 0.97558, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.0869 - val_accuracy: 0.9756\n",
            "Epoch 11/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9955\n",
            "Epoch 11: val_accuracy did not improve from 0.97558\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.0863 - val_accuracy: 0.9753\n",
            "Epoch 12/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy improved from 0.97558 to 0.97617, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.0872 - val_accuracy: 0.9762\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9975\n",
            "Epoch 13: val_accuracy did not improve from 0.97617\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 0.0902 - val_accuracy: 0.9757\n",
            "Epoch 14/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9985\n",
            "Epoch 14: val_accuracy did not improve from 0.97617\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0928 - val_accuracy: 0.9757\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTFcc7ueBdsV",
        "outputId": "0453f3ad-d438-4b9d-db27-dd530bfd204c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9790\n",
            "Test Accuracy: 0.9789999723434448\n"
          ]
        }
      ],
      "source": [
        "best_model = keras.models.load_model('best_model.h5')\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test Accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLvrbJShB7gy",
        "outputId": "31083992-ff30-47ec-e070-b58650924135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "Precision: 0.9976752\n",
            "Recall: 0.9991131\n",
            "F1 Score: 0.99839365\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(x_test)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)\n",
        "true_labels = tf.argmax(y_test, axis=1)\n",
        "\n",
        "precision = tf.keras.metrics.Precision()(true_labels, predicted_labels)\n",
        "recall = tf.keras.metrics.Recall()(true_labels, predicted_labels)\n",
        "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
        "\n",
        "print('Precision:', precision.numpy())\n",
        "print('Recall:', recall.numpy())\n",
        "print('F1 Score:', f1_score.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU7pdH7wEtKS"
      },
      "source": [
        "Question 3\n",
        "---\n",
        "**let's experiment with different optimizers. We'll modify the optimizer used in the model and compile it before training.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RXPgMnZGSbb"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e9ieZmBCP2T",
        "outputId": "9cdea3b5-59dc-4f65-827a-5ee0eed63f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with optimizer: sgd\n",
            "Epoch 1/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993\n",
            "Epoch 1: val_accuracy improved from 0.97617 to 0.97633, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 8ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0890 - val_accuracy: 0.9763\n",
            "Epoch 2/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9994\n",
            "Epoch 2: val_accuracy did not improve from 0.97633\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0882 - val_accuracy: 0.9763\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9995\n",
            "Epoch 3: val_accuracy improved from 0.97633 to 0.97642, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0877 - val_accuracy: 0.9764\n",
            "Epoch 4/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9996\n",
            "Epoch 4: val_accuracy improved from 0.97642 to 0.97675, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0873 - val_accuracy: 0.9768\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9996\n",
            "Epoch 5: val_accuracy did not improve from 0.97675\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0870 - val_accuracy: 0.9768\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9996\n",
            "Epoch 6: val_accuracy improved from 0.97675 to 0.97700, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0869 - val_accuracy: 0.9770\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9996\n",
            "Epoch 7: val_accuracy improved from 0.97700 to 0.97708, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
            "Epoch 8/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9996\n",
            "Epoch 8: val_accuracy did not improve from 0.97708\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0866 - val_accuracy: 0.9769\n",
            "Epoch 9/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9996\n",
            "Epoch 9: val_accuracy did not improve from 0.97708\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0865 - val_accuracy: 0.9770\n",
            "Epoch 10/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9996\n",
            "Epoch 10: val_accuracy did not improve from 0.97708\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0864 - val_accuracy: 0.9769\n",
            "Epoch 11/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9997\n",
            "Epoch 11: val_accuracy did not improve from 0.97708\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.0863 - val_accuracy: 0.9770\n",
            "Epoch 12/20\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997\n",
            "Epoch 12: val_accuracy improved from 0.97708 to 0.97717, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0862 - val_accuracy: 0.9772\n",
            "Epoch 13/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997\n",
            "Epoch 13: val_accuracy did not improve from 0.97717\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0861 - val_accuracy: 0.9772\n",
            "Epoch 14/20\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n",
            "Epoch 14: val_accuracy improved from 0.97717 to 0.97725, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0862 - val_accuracy: 0.9772\n",
            "Epoch 15/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n",
            "Epoch 15: val_accuracy improved from 0.97725 to 0.97733, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0861 - val_accuracy: 0.9773\n",
            "Epoch 16/20\n",
            "369/375 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997\n",
            "Epoch 16: val_accuracy did not improve from 0.97733\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0860 - val_accuracy: 0.9772\n",
            "Epoch 17/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997\n",
            "Epoch 17: val_accuracy improved from 0.97733 to 0.97742, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0860 - val_accuracy: 0.9774\n",
            "Epoch 18/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997\n",
            "Epoch 18: val_accuracy did not improve from 0.97742\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0859 - val_accuracy: 0.9774\n",
            "Epoch 19/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9997\n",
            "Epoch 19: val_accuracy did not improve from 0.97742\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0859 - val_accuracy: 0.9774\n",
            "Epoch 20/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9997\n",
            "Epoch 20: val_accuracy improved from 0.97742 to 0.97750, saving model to best_model.h5\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0859 - val_accuracy: 0.9775\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.9796\n",
            "Test Accuracy: 0.9796000123023987\n",
            "------------------------------------\n",
            "Training model with optimizer: rmsprop\n",
            "Epoch 1/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9988\n",
            "Epoch 1: val_accuracy improved from 0.97750 to 0.97767, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0883 - val_accuracy: 0.9777\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9992\n",
            "Epoch 2: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0978 - val_accuracy: 0.9772\n",
            "Epoch 3/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9992\n",
            "Epoch 3: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0985 - val_accuracy: 0.9772\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994\n",
            "Epoch 4: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0994 - val_accuracy: 0.9773\n",
            "Epoch 4: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9787\n",
            "Test Accuracy: 0.9786999821662903\n",
            "------------------------------------\n",
            "Training model with optimizer: adam\n",
            "Epoch 1/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n",
            "Epoch 1: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 9ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1167 - val_accuracy: 0.9747\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
            "Epoch 2: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1051 - val_accuracy: 0.9770\n",
            "Epoch 3/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 3: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1196 - val_accuracy: 0.9747\n",
            "Epoch 4/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9947\n",
            "Epoch 4: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1141 - val_accuracy: 0.9753\n",
            "Epoch 5/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
            "Epoch 5: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.1115 - val_accuracy: 0.9748\n",
            "Epoch 5: early stopping\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.9787\n",
            "Test Accuracy: 0.9786999821662903\n",
            "------------------------------------\n",
            "Training model with optimizer: adagrad\n",
            "Epoch 1/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 1: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 8ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1081 - val_accuracy: 0.9759\n",
            "Epoch 2/20\n",
            "368/375 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 2: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1068 - val_accuracy: 0.9765\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999\n",
            "Epoch 3: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.1063 - val_accuracy: 0.9767\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9768\n",
            "Epoch 5/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9767\n",
            "Epoch 6/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 9.6038e-04 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 9.5681e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9766\n",
            "Epoch 7/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 9.1819e-04 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 9.1634e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9766\n",
            "Epoch 8/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 8.8541e-04 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 8.8564e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9766\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 8.6143e-04 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 8.6143e-04 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9765\n",
            "Epoch 10/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 8.3258e-04 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 8.4156e-04 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9767\n",
            "Epoch 11/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 8.2499e-04 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 8.2484e-04 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9767\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 8.1046e-04 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 8.1046e-04 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9767\n",
            "Epoch 13/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 8.0106e-04 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 7.9789e-04 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9767\n",
            "Epoch 14/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.8648e-04 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 7.8675e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 7.7674e-04 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.7674e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 16/20\n",
            "368/375 [============================>.] - ETA: 0s - loss: 7.7257e-04 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 7.6767e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9769\n",
            "Epoch 17/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 7.6015e-04 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 7.5941e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9770\n",
            "Epoch 18/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.4993e-04 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 7.5179e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9768\n",
            "Epoch 19/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 7.4488e-04 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 7.4476e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9770\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 7.3821e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 7.3821e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9787\n",
            "Test Accuracy: 0.9786999821662903\n",
            "------------------------------------\n",
            "Training model with optimizer: adadelta\n",
            "Epoch 1/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 7.3734e-04 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 7s 15ms/step - loss: 7.3337e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 7.3170e-04 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.3170e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 3/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 7.3035e-04 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.3008e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 4/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.2749e-04 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 7.2848e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 5/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 7.2973e-04 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.2689e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 6/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 7.2379e-04 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.2535e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9771\n",
            "Epoch 7/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.2447e-04 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 7.2383e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9771\n",
            "Epoch 8/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.2106e-04 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.2233e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9770\n",
            "Epoch 9/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 7.2115e-04 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.2085e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9769\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 7.1938e-04 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 7.1938e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9769\n",
            "Epoch 11/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.1823e-04 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.1796e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9768\n",
            "Epoch 12/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 7.1697e-04 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.1654e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9769\n",
            "Epoch 13/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 7.1551e-04 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 7.1515e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9770\n",
            "Epoch 14/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 7.1558e-04 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.1378e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9770\n",
            "Epoch 15/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 7.1009e-04 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 7.1242e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9770\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 7.1110e-04 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.1110e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9771\n",
            "Epoch 17/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 7.0701e-04 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 7.0977e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9771\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 7.0847e-04 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.0847e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9771\n",
            "Epoch 19/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 7.0766e-04 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 7.0719e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9771\n",
            "Epoch 20/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 7.0752e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.97767\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 7.0592e-04 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9771\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0798 - accuracy: 0.9787\n",
            "Test Accuracy: 0.9786999821662903\n",
            "------------------------------------\n",
            "Training model with optimizer: adamax\n",
            "Epoch 1/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 7.0852e-04 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from 0.97767 to 0.97775, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 11ms/step - loss: 7.0977e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
            "Epoch 2/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 4.1800e-04 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy improved from 0.97775 to 0.97808, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 4.1674e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9781\n",
            "Epoch 3/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 3.5092e-04 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy improved from 0.97808 to 0.97825, saving model to best_model.h5\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 3.5315e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9783\n",
            "Epoch 4/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 2.9516e-04 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97825\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.9524e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9780\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 2.5260e-04 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy improved from 0.97825 to 0.97875, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 2.5260e-04 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9787\n",
            "Epoch 5: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9796\n",
            "Test Accuracy: 0.9796000123023987\n",
            "------------------------------------\n",
            "Training model with optimizer: nadam\n",
            "Epoch 1/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 1: val_accuracy did not improve from 0.97875\n",
            "375/375 [==============================] - 6s 11ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1251 - val_accuracy: 0.9751\n",
            "Epoch 2/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 2: val_accuracy improved from 0.97875 to 0.97908, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1186 - val_accuracy: 0.9791\n",
            "Epoch 3/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 3: val_accuracy did not improve from 0.97908\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1198 - val_accuracy: 0.9762\n",
            "Epoch 4/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
            "Epoch 4: val_accuracy did not improve from 0.97908\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1323 - val_accuracy: 0.9753\n",
            "Epoch 5/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 5: val_accuracy did not improve from 0.97908\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1379 - val_accuracy: 0.9752\n",
            "Epoch 5: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1081 - accuracy: 0.9779\n",
            "Test Accuracy: 0.9779000282287598\n",
            "------------------------------------\n",
            "Test Accuracies for Different Optimizers:\n",
            "sgd: 0.9796000123023987\n",
            "rmsprop: 0.9786999821662903\n",
            "adam: 0.9786999821662903\n",
            "adagrad: 0.9786999821662903\n",
            "adadelta: 0.9786999821662903\n",
            "adamax: 0.9796000123023987\n",
            "nadam: 0.9779000282287598\n"
          ]
        }
      ],
      "source": [
        "optimizers = ['sgd', 'rmsprop', 'adam', 'adagrad', 'adadelta', 'adamax', 'nadam']\n",
        "Test_Accuracy=[];\n",
        "\n",
        "for optimizer_name in optimizers:\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    \n",
        "    optimizer = keras.optimizers.get(optimizer_name)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    print(f\"Training model with optimizer: {optimizer_name}\")\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "    \n",
        "    best_model = keras.models.load_model('best_model.h5')\n",
        "    \n",
        "    test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "    \n",
        "    Test_Accuracy.append(test_accuracy)\n",
        "    print('Test Accuracy:', test_accuracy)\n",
        "    print('------------------------------------')\n",
        "print(\"Test Accuracies for Different Optimizers:\")\n",
        "for i in range(len(optimizers)):\n",
        "    print(f\"{optimizers[i]}: {Test_Accuracy[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabnbhSGI5ty"
      },
      "source": [
        "Question 4\n",
        "---\n",
        "**This time implement different regularization methods such as L1, L2, and Dropout to reduce overfitting.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSSGLvk7FME9",
        "outputId": "5fdc0e6a-2a28-462b-d7ec-eb6e9ec4ac51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 7.8904 - accuracy: 0.7650\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90767, saving model to best_model.h5\n",
            "375/375 [==============================] - 6s 13ms/step - loss: 7.8172 - accuracy: 0.7662 - val_loss: 0.8511 - val_accuracy: 0.9077\n",
            "Epoch 2/20\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.8543\n",
            "Epoch 2: val_accuracy did not improve from 0.90767\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.9258 - accuracy: 0.8545 - val_loss: 0.7427 - val_accuracy: 0.8974\n",
            "Epoch 3/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.8528 - accuracy: 0.8632\n",
            "Epoch 3: val_accuracy did not improve from 0.90767\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.8528 - accuracy: 0.8629 - val_loss: 0.7015 - val_accuracy: 0.9050\n",
            "Epoch 4/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.8282 - accuracy: 0.8647\n",
            "Epoch 4: val_accuracy improved from 0.90767 to 0.90883, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.8284 - accuracy: 0.8647 - val_loss: 0.6844 - val_accuracy: 0.9088\n",
            "Epoch 5/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.8116 - accuracy: 0.8674\n",
            "Epoch 5: val_accuracy did not improve from 0.90883\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.8118 - accuracy: 0.8674 - val_loss: 0.6683 - val_accuracy: 0.9078\n",
            "Epoch 6/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.8013 - accuracy: 0.8693\n",
            "Epoch 6: val_accuracy did not improve from 0.90883\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.8012 - accuracy: 0.8694 - val_loss: 0.6720 - val_accuracy: 0.9015\n",
            "Epoch 7/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7941 - accuracy: 0.8679\n",
            "Epoch 7: val_accuracy did not improve from 0.90883\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.7940 - accuracy: 0.8680 - val_loss: 0.6577 - val_accuracy: 0.9072\n",
            "Epoch 8/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.7839 - accuracy: 0.8701\n",
            "Epoch 8: val_accuracy did not improve from 0.90883\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.7839 - accuracy: 0.8700 - val_loss: 0.6533 - val_accuracy: 0.9078\n",
            "Epoch 9/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.7825 - accuracy: 0.8691\n",
            "Epoch 9: val_accuracy improved from 0.90883 to 0.90942, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.7828 - accuracy: 0.8691 - val_loss: 0.6414 - val_accuracy: 0.9094\n",
            "Epoch 10/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.7755 - accuracy: 0.8687\n",
            "Epoch 10: val_accuracy did not improve from 0.90942\n",
            "375/375 [==============================] - 5s 15ms/step - loss: 0.7753 - accuracy: 0.8688 - val_loss: 0.6441 - val_accuracy: 0.9068\n",
            "Epoch 11/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7720 - accuracy: 0.8694\n",
            "Epoch 11: val_accuracy improved from 0.90942 to 0.91217, saving model to best_model.h5\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.7723 - accuracy: 0.8693 - val_loss: 0.6352 - val_accuracy: 0.9122\n",
            "Epoch 12/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.7713 - accuracy: 0.8703\n",
            "Epoch 12: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7714 - accuracy: 0.8701 - val_loss: 0.6304 - val_accuracy: 0.9082\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.7660 - accuracy: 0.8711\n",
            "Epoch 13: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.7660 - accuracy: 0.8711 - val_loss: 0.6282 - val_accuracy: 0.9087\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.7604 - accuracy: 0.8700\n",
            "Epoch 14: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.7604 - accuracy: 0.8700 - val_loss: 0.6411 - val_accuracy: 0.9029\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.7628 - accuracy: 0.8722\n",
            "Epoch 15: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.7628 - accuracy: 0.8722 - val_loss: 0.6259 - val_accuracy: 0.9107\n",
            "Epoch 16/20\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.7554 - accuracy: 0.8719\n",
            "Epoch 16: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.7560 - accuracy: 0.8715 - val_loss: 0.6436 - val_accuracy: 0.9053\n",
            "Epoch 17/20\n",
            "374/375 [============================>.] - ETA: 0s - loss: 0.7591 - accuracy: 0.8702\n",
            "Epoch 17: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.7590 - accuracy: 0.8703 - val_loss: 0.6285 - val_accuracy: 0.9054\n",
            "Epoch 18/20\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.7571 - accuracy: 0.8717\n",
            "Epoch 18: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.7569 - accuracy: 0.8719 - val_loss: 0.6177 - val_accuracy: 0.9118\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.7587 - accuracy: 0.8705\n",
            "Epoch 19: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.7587 - accuracy: 0.8705 - val_loss: 0.6219 - val_accuracy: 0.9080\n",
            "Epoch 20/20\n",
            "372/375 [============================>.] - ETA: 0s - loss: 0.7563 - accuracy: 0.8696\n",
            "Epoch 20: val_accuracy did not improve from 0.91217\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7558 - accuracy: 0.8699 - val_loss: 0.6291 - val_accuracy: 0.9084\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6390 - accuracy: 0.9104\n",
            "Test Accuracy: 0.9103999733924866\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "input_layer = Input(shape=(28, 28))\n",
        "\n",
        "flatten_layer = keras.layers.Flatten()(input_layer)\n",
        "\n",
        "wide_branch = Dense(128, activation='tanh', kernel_regularizer=l2(0.01))(flatten_layer)\n",
        "wide_branch = Dropout(0.5)(wide_branch)\n",
        "wide_branch = Dense(64, activation='tanh', kernel_regularizer=l2(0.01))(wide_branch)\n",
        "wide_branch = Dropout(0.5)(wide_branch)\n",
        "\n",
        "deep_branch = Dense(128, activation='sigmoid', kernel_regularizer=l1(0.01))(flatten_layer)\n",
        "deep_branch = Dropout(0.5)(deep_branch)\n",
        "deep_branch = Dense(128, activation='sigmoid', kernel_regularizer=l1(0.01))(deep_branch)\n",
        "deep_branch = Dropout(0.5)(deep_branch)\n",
        "deep_branch = Dense(64, activation='sigmoid', kernel_regularizer=l1(0.01))(deep_branch)\n",
        "deep_branch = Dropout(0.5)(deep_branch)\n",
        "\n",
        "concat_layer = Concatenate()([wide_branch, deep_branch])\n",
        "\n",
        "output_layer = Dense(10, activation='softmax')(concat_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "best_model = keras.models.load_model('best_model.h5')\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "054bt9XgLJhR"
      },
      "source": [
        "Question 5\n",
        "---\n",
        "Implementing ResNet-34 architecture from the scratch using Keras Sequential API. then train the network to predict on MNIST Fashion dataset. Evaluate model using appropriate metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaotFjXFJMES",
        "outputId": "2582a9b6-0783-42cb-9395-fc301c61d2cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.8275\n",
            "Epoch 1: val_accuracy improved from -inf to 0.61683, saving model to best_model.h5\n",
            "375/375 [==============================] - 3224s 9s/step - loss: 0.4783 - accuracy: 0.8275 - val_loss: 1.1706 - val_accuracy: 0.6168\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.8837\n",
            "Epoch 2: val_accuracy improved from 0.61683 to 0.81575, saving model to best_model.h5\n",
            "375/375 [==============================] - 3295s 9s/step - loss: 0.3187 - accuracy: 0.8837 - val_loss: 0.5929 - val_accuracy: 0.8158\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.8961\n",
            "Epoch 3: val_accuracy improved from 0.81575 to 0.82042, saving model to best_model.h5\n",
            "375/375 [==============================] - 3570s 10s/step - loss: 0.2821 - accuracy: 0.8961 - val_loss: 0.5632 - val_accuracy: 0.8204\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9056\n",
            "Epoch 4: val_accuracy improved from 0.82042 to 0.86017, saving model to best_model.h5\n",
            "375/375 [==============================] - 3283s 9s/step - loss: 0.2557 - accuracy: 0.9056 - val_loss: 0.4063 - val_accuracy: 0.8602\n",
            "Epoch 5/20\n",
            "124/375 [========>.....................] - ETA: 34:15 - loss: 0.2404 - accuracy: 0.9112"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Expand dimensions for grayscale images\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Define the Residual Block\n",
        "def residual_block(x, filters, strides=1):\n",
        "    shortcut = x\n",
        "    \n",
        "    # First convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # Second convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    # If the number of filters changes or the strides are greater than 1, apply a convolution to shortcut path\n",
        "    if strides > 1 or shortcut.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "    \n",
        "    # Add the shortcut to the main path\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Build the ResNet-34 model\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(64, kernel_size=(7, 7), strides=2, padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "x = residual_block(x, filters=64)\n",
        "x = residual_block(x, filters=64)\n",
        "x = residual_block(x, filters=64)\n",
        "\n",
        "x = residual_block(x, filters=128, strides=2)\n",
        "x = residual_block(x, filters=128)\n",
        "x = residual_block(x, filters=128)\n",
        "x = residual_block(x, filters=128)\n",
        "\n",
        "x = residual_block(x, filters=256, strides=2)\n",
        "x = residual_block(x, filters=256)\n",
        "x = residual_block(x, filters=256)\n",
        "x = residual_block(x, filters=256)\n",
        "x = residual_block(x, filters=256)\n",
        "x = residual_block(x, filters=256)\n",
        "\n",
        "x = residual_block(x, filters=512, strides=2)\n",
        "x = residual_block(x, filters=512)\n",
        "x = residual_block(x, filters=512)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Flatten()(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up early stopping and model checkpoint callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Load the best model saved during training\n",
        "best_model = keras.models.load_model('best_model.h5')\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpXvjwnLErVo"
      },
      "source": [
        "Question 6\n",
        "---\n",
        "**Now train the same dataset and the same ResNet-34, but use pre-trained weights. In other words, use transfer learning to train the same model and determine whether there is any improvement in training time, accuracy, or any other aspect.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "tiDh6VpJMKR8",
        "outputId": "529eb8bb-c146-4512-de8e-cf9337747bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7adb767651f8>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Preprocess the input data for transfer learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(x, data_format)\u001b[0m\n\u001b[1;32m    609\u001b[0m )\n\u001b[1;32m    610\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     return imagenet_utils.preprocess_input(\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"caffe\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(x, data_format, mode)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_preprocess_numpy_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_preprocess_symbolic_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_preprocess_numpy_input\u001b[0;34m(x, data_format, mode)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 3 with size 1"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add\n",
        "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Expand dimensions for grayscale images\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Preprocess the input data for transfer learning\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)\n",
        "\n",
        "# Load the pre-trained ResNet-50 model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(28, 28, 3))\n",
        "\n",
        "# Add a new classification head on top of the pre-trained base model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the transfer learning model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test Accuracy: ', test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}